{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ed4ab92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Subset, Dataset\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os, random, time, io\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import kagglehub\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility + device\n",
    "SEED = 56\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd17c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if a graphics card (GPU) is available for faster training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device being used:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset (Kaggle)\n",
    "# Dataset: alistairking/recyclable-and-household-waste-classification\n",
    "print(\"Downloading dataset...\")\n",
    "ds_path = kagglehub.dataset_download(\n",
    "    \"alistairking/recyclable-and-household-waste-classification\"\n",
    ")\n",
    "print(\"Dataset downloaded to:\", ds_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f64c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Kaggle datasets have extra folders like \"images/images\"\n",
    "# This loop finds the real folder that contains all the image categories.\n",
    "candidates = [\n",
    "    Path(path) / \"images\" / \"images\",\n",
    "    Path(path) / \"images\",\n",
    "    Path(path),\n",
    "]\n",
    "\n",
    "DATA_ROOT = None\n",
    "for c in candidates:\n",
    "    if c.exists() and any(d.is_dir() for d in c.iterdir()):\n",
    "        DATA_ROOT = c\n",
    "        break\n",
    "\n",
    "if DATA_ROOT is None:\n",
    "    raise FileNotFoundError(f\"Could not find image folder in: {path}\")\n",
    "\n",
    "print(\"Image root folder found:\", DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build full ImageFolder (PNG-only filter)\n",
    "png_only = lambda p: str(p).lower().endswith(\".png\")\n",
    "full_ds = datasets.ImageFolder(root=str(DATA_ROOT), transform=None, is_valid_file=png_only)\n",
    "class_names: List[str] = full_ds.classes\n",
    "num_classes = len(class_names)\n",
    "print(f\"Classes ({num_classes}):\", class_names[:10], \"...\" if num_classes > 10 else \"\")\n",
    "print(\"Total PNG images:\", len(full_ds.samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f77e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Check what categories (folders) exist ---\n",
    "# Each folder inside the dataset represents one type of waste.\n",
    "class_dirs = sorted([d.name for d in DATA_ROOT.iterdir() if d.is_dir()])\n",
    "print(\"Number of categories found:\", len(class_dirs))\n",
    "print(\"Example categories:\", class_dirs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bad3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define image transformations (resizing and data augmentation) ---\n",
    "# These changes help prepare the photos before training the model.\n",
    "\n",
    "IMG_SIZE = 224  # final image size (in pixels)\n",
    "\n",
    "# Training transformations (adds small random changes for variety)\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),             # make all images similar size\n",
    "    transforms.RandomResizedCrop(IMG_SIZE,     # randomly crop and resize\n",
    "                                 scale=(0.8, 1.0),\n",
    "                                 ratio=(0.9, 1.1)),\n",
    "    transforms.RandomHorizontalFlip(),         # randomly flip images left-right\n",
    "    transforms.RandomRotation(10),             # rotate slightly (±10°)\n",
    "    transforms.ColorJitter(                    # small colour adjustments\n",
    "        brightness=0.10, contrast=0.10, saturation=0.10, hue=0.05),\n",
    "    transforms.ToTensor(),                     # turn image into numeric array\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # standard colour scaling\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c172e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation/testing transformations (simpler, no random changes)\n",
    "eval_tf = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Filter function: only include .png or .PNG images\n",
    "png_only = lambda p: str(p).lower().endswith(\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the dataset ---\n",
    "# Organises images into labelled groups using their folder names.\n",
    "full_ds = datasets.ImageFolder(\n",
    "    root=str(DATA_ROOT),\n",
    "    transform=None,          # we'll apply transforms later\n",
    "    is_valid_file=png_only   # only include PNG files\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e732792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a quick summary\n",
    "num_classes = len(full_ds.classes)\n",
    "print(f\"Total number of categories: {num_classes}\")\n",
    "print(\"First few category names:\", full_ds.classes[:10])\n",
    "print(\"Total number of images:\", len(full_ds.samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
