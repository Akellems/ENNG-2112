{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trashnet Dataset Training\n",
        "Training MobileNetV3-Small and ViT-Small models on the garythung/trashnet dataset (6 classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Loading and Preprocessing\n",
        "from __future__ import annotations\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Optional, Dict\n",
        "import platform\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from datasets import load_dataset\n",
        "\n",
        "print(\"Imports successful!\")\n",
        "\n",
        "# Reproducibility\n",
        "def set_seed(seed: int = 56) -> None:\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def get_num_workers(requested_workers: int = 2) -> int:\n",
        "    \"\"\"Windows-safe num_workers configuration\"\"\"\n",
        "    if platform.system() == 'Windows':\n",
        "        print(f\"[Platform] Windows detected: Using num_workers=0\")\n",
        "        return 0\n",
        "    return requested_workers\n",
        "\n",
        "set_seed(56)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HuggingFace Dataset Wrapper\n",
        "class HuggingFaceImageDataset(Dataset):\n",
        "    \"\"\"Wraps a HuggingFace dataset with PyTorch transforms.\"\"\"\n",
        "    \n",
        "    def __init__(self, hf_dataset, transform=None, label_key=\"label\", image_key=\"image\"):\n",
        "        self.dataset = hf_dataset\n",
        "        self.transform = transform\n",
        "        self.label_key = label_key\n",
        "        self.image_key = image_key\n",
        "        \n",
        "        # Extract class names and targets for weighted sampling\n",
        "        if hasattr(hf_dataset.features[label_key], 'names'):\n",
        "            self.classes = hf_dataset.features[label_key].names\n",
        "        else:\n",
        "            self.classes = []\n",
        "        \n",
        "        # Pre-extract all labels for weighted sampler\n",
        "        self.targets = [item[label_key] for item in hf_dataset]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        image = item[self.image_key]\n",
        "        label = item[self.label_key]\n",
        "        \n",
        "        # Convert to PIL Image if not already\n",
        "        if not isinstance(image, Image.Image):\n",
        "            image = Image.fromarray(image)\n",
        "        \n",
        "        # Ensure RGB mode\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "print(\"✓ Dataset wrapper defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Trashnet Dataset\n",
        "print(\"[HuggingFace] Loading trashnet dataset...\")\n",
        "ds = load_dataset(\"garythung/trashnet\")\n",
        "\n",
        "print(f\"[Dataset] Available splits: {list(ds.keys())}\")\n",
        "print(f\"[Dataset] Total samples: {len(ds['train'])}\")\n",
        "\n",
        "# Create train/val split (80/20)\n",
        "train_val_split = ds['train'].train_test_split(test_size=0.2, seed=56)\n",
        "\n",
        "# Define transforms (matching ImageNet preprocessing)\n",
        "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
        "])\n",
        "\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_ds = HuggingFaceImageDataset(train_val_split['train'], transform=train_tfms)\n",
        "val_ds = HuggingFaceImageDataset(train_val_split['test'], transform=val_tfms)\n",
        "\n",
        "num_classes = len(train_ds.classes)\n",
        "print(f\"\\n✓ Classes ({num_classes}): {train_ds.classes}\")\n",
        "print(f\"✓ Train samples: {len(train_ds)}\")\n",
        "print(f\"✓ Val samples: {len(val_ds)}\")\n",
        "\n",
        "# Create weighted sampler for class balancing\n",
        "train_targets = np.array(train_ds.targets)\n",
        "counts = np.bincount(train_targets)\n",
        "class_weights = 1.0 / np.clip(counts, 1, None)\n",
        "sample_weights = class_weights[train_targets]\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(train_ds), replacement=True)\n",
        "\n",
        "print(f\"\\n✓ Class distribution (train):\")\n",
        "for i, cls in enumerate(train_ds.classes):\n",
        "    print(f\"  {cls:15s}: {counts[i]:4d} samples (weight: {class_weights[i]:.3f})\")\n",
        "\n",
        "# Create DataLoaders\n",
        "num_workers = get_num_workers(4)\n",
        "train_dl = DataLoader(train_ds, batch_size=64, sampler=sampler, \n",
        "                      num_workers=num_workers, pin_memory=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=128, shuffle=False, \n",
        "                    num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "print(f\"\\n✓ DataLoaders created (num_workers={num_workers})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Models\n",
        "import timm\n",
        "from torch import nn\n",
        "\n",
        "def make_model(name, num_classes):\n",
        "    \"\"\"Create a pretrained model with dropout regularization\"\"\"\n",
        "    m = timm.create_model(name, pretrained=True, drop_rate=0.2, drop_path_rate=0.1, num_classes=num_classes)\n",
        "    return m\n",
        "\n",
        "# Create MobileNetV3-Small and ViT-Small\n",
        "mobilenet_small = make_model(\"mobilenetv3_small_100\", num_classes)\n",
        "vit_small = make_model(\"vit_small_patch16_224\", num_classes)\n",
        "\n",
        "print(f\"✓ MobileNetV3-Small params: {sum(p.numel() for p in mobilenet_small.parameters())/1e6:.2f}M\")\n",
        "print(f\"✓ ViT-Small params: {sum(p.numel() for p in vit_small.parameters())/1e6:.2f}M\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training Function with Mixed Precision\n",
        "from torch.amp import autocast, GradScaler\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "def train_model(model, train_dl, val_dl, epochs=20, lr=5e-4, wd=0.05, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Train a model with:\n",
        "    - Mixed precision training\n",
        "    - AdamW optimizer with weight decay\n",
        "    - Linear warmup (3 epochs) + Cosine annealing\n",
        "    - Label smoothing\n",
        "    - Best model checkpointing based on macro F1\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    \n",
        "    # Learning rate schedule: warmup + cosine\n",
        "    warmup = torch.optim.lr_scheduler.LinearLR(opt, start_factor=0.1, total_iters=3)\n",
        "    cosine = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs-3)\n",
        "    sched = torch.optim.lr_scheduler.SequentialLR(opt, [warmup, cosine], milestones=[3])\n",
        "    \n",
        "    crit = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    scaler = GradScaler('cuda', enabled=(device.startswith(\"cuda\")))\n",
        "    best = {\"f1\": -1, \"state\": None, \"epoch\": 0}\n",
        "    \n",
        "    for ep in range(epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x, y in train_dl:\n",
        "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            \n",
        "            with autocast('cuda', enabled=(device.startswith(\"cuda\"))):\n",
        "                logits = model(x)\n",
        "                loss = crit(logits, y)\n",
        "            \n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "            train_loss += loss.item()\n",
        "        \n",
        "        sched.step()\n",
        "        \n",
        "        # Validation\n",
        "        model.eval()\n",
        "        preds, gts = [], []\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_dl:\n",
        "                x = x.to(device, non_blocking=True)\n",
        "                logits = model(x)\n",
        "                preds.append(logits.argmax(1).cpu())\n",
        "                gts.append(y)\n",
        "        \n",
        "        p = torch.cat(preds).numpy()\n",
        "        g = torch.cat(gts).numpy()\n",
        "        f1 = f1_score(g, p, average=\"macro\")\n",
        "        acc = accuracy_score(g, p)\n",
        "        \n",
        "        # Save best model\n",
        "        if f1 > best[\"f1\"]:\n",
        "            best = {\"f1\": f1, \"state\": model.state_dict(), \"epoch\": ep+1}\n",
        "        \n",
        "        print(f\"ep {ep+1:2d}: acc {acc:.4f}  macroF1 {f1:.4f}  (best F1: {best['f1']:.4f} @ ep{best['epoch']})\")\n",
        "    \n",
        "    # Load best model\n",
        "    model.load_state_dict(best[\"state\"])\n",
        "    print(f\"\\n✓ Training complete. Best model from epoch {best['epoch']} (F1: {best['f1']:.4f})\")\n",
        "    return model\n",
        "\n",
        "print(\"✓ Training function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check CUDA availability\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    print(\"Device: CPU\")\n",
        "    device = \"cpu\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train MobileNetV3-Small\n",
        "print(\"=\"*60)\n",
        "print(\"TRAINING MOBILENETV3-SMALL\")\n",
        "print(\"=\"*60)\n",
        "mobilenet_trained = train_model(mobilenet_small, train_dl, val_dl, epochs=20, lr=5e-4, wd=0.05, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train ViT-Small\n",
        "# ViT typically needs slightly lower learning rate\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING VIT-SMALL\")\n",
        "print(\"=\"*60)\n",
        "vit_trained = train_model(vit_small, train_dl, val_dl, epochs=20, lr=3e-4, wd=0.05, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance Comparison and Benchmarking\n",
        "import time\n",
        "\n",
        "def ms_per_image(model, device=\"cuda\"):\n",
        "    \"\"\"Measure inference speed in milliseconds per image\"\"\"\n",
        "    model.eval().to(device)\n",
        "    x = torch.randn(1, 3, 224, 224, device=device)\n",
        "    \n",
        "    # Warmup\n",
        "    for _ in range(5):\n",
        "        model(x)\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.synchronize()\n",
        "    \n",
        "    # Benchmark\n",
        "    t0 = time.time()\n",
        "    for _ in range(50):\n",
        "        model(x)\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.synchronize()\n",
        "    \n",
        "    return 1000 * (time.time() - t0) / 50\n",
        "\n",
        "def get_final_metrics(model, val_dl, device):\n",
        "    \"\"\"Get final accuracy and F1 score\"\"\"\n",
        "    model.eval().to(device)\n",
        "    preds, gts = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_dl:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            logits = model(x)\n",
        "            preds.append(logits.argmax(1).cpu())\n",
        "            gts.append(y)\n",
        "    \n",
        "    p = torch.cat(preds).numpy()\n",
        "    g = torch.cat(gts).numpy()\n",
        "    return accuracy_score(g, p), f1_score(g, p, average=\"macro\")\n",
        "\n",
        "# Inference speed comparison\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"INFERENCE SPEED COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "mobilenet_speed = ms_per_image(mobilenet_trained, device)\n",
        "vit_speed = ms_per_image(vit_trained, device)\n",
        "print(f\"MobileNetV3-Small: {mobilenet_speed:.2f} ms/image\")\n",
        "print(f\"ViT-Small:         {vit_speed:.2f} ms/image\")\n",
        "print(f\"Speed ratio:       {vit_speed/mobilenet_speed:.2f}x (ViT/MobileNet)\")\n",
        "\n",
        "# Final validation performance\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL VALIDATION PERFORMANCE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "models = [\n",
        "    (\"MobileNetV3-Small\", mobilenet_trained),\n",
        "    (\"ViT-Small\", vit_trained)\n",
        "]\n",
        "\n",
        "results = []\n",
        "for name, model in models:\n",
        "    acc, f1 = get_final_metrics(model, val_dl, device)\n",
        "    params = sum(p.numel() for p in model.parameters()) / 1e6\n",
        "    speed = ms_per_image(model, device)\n",
        "    results.append((name, acc, f1, params, speed))\n",
        "    print(f\"{name:20s} | Acc: {acc:.4f} | F1: {f1:.4f} | Params: {params:.2f}M | Speed: {speed:.2f}ms\")\n",
        "\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save Models\n",
        "# Save MobileNetV3-Small in PyTorch and ONNX formats\n",
        "torch.save({\n",
        "    \"model\": \"mobilenetv3_small_100\",\n",
        "    \"classes\": train_ds.classes,\n",
        "    \"num_classes\": num_classes,\n",
        "    \"state_dict\": mobilenet_trained.state_dict(),\n",
        "    \"dataset\": \"garythung/trashnet\"\n",
        "}, \"mobilenetv3_small_trashnet.pt\")\n",
        "\n",
        "# Export to ONNX for deployment\n",
        "dummy = torch.randn(1, 3, 224, 224)\n",
        "mobilenet_trained.eval().cpu()\n",
        "torch.onnx.export(\n",
        "    mobilenet_trained, \n",
        "    dummy, \n",
        "    \"mobilenetv3_small_trashnet.onnx\",\n",
        "    input_names=[\"input\"], \n",
        "    output_names=[\"logits\"], \n",
        "    opset_version=17,\n",
        "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"logits\": {0: \"batch_size\"}}\n",
        ")\n",
        "\n",
        "# Save ViT-Small\n",
        "torch.save({\n",
        "    \"model\": \"vit_small_patch16_224\",\n",
        "    \"classes\": train_ds.classes,\n",
        "    \"num_classes\": num_classes,\n",
        "    \"state_dict\": vit_trained.state_dict(),\n",
        "    \"dataset\": \"garythung/trashnet\"\n",
        "}, \"vit_small_trashnet.pt\")\n",
        "\n",
        "print(\"✓ Saved MobileNetV3-Small:\")\n",
        "print(\"  - mobilenetv3_small_trashnet.pt (PyTorch)\")\n",
        "print(\"  - mobilenetv3_small_trashnet.onnx (ONNX)\")\n",
        "print(\"✓ Saved ViT-Small:\")\n",
        "print(\"  - vit_small_trashnet.pt (PyTorch)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Confusion Matrix Analysis\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(model, val_dl, classes, device, title=\"Confusion Matrix\"):\n",
        "    \"\"\"Plot confusion matrix for model predictions\"\"\"\n",
        "    model.eval().to(device)\n",
        "    preds, gts = [], []\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_dl:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            logits = model(x)\n",
        "            preds.append(logits.argmax(1).cpu())\n",
        "            gts.append(y)\n",
        "    \n",
        "    p = torch.cat(preds).numpy()\n",
        "    g = torch.cat(gts).numpy()\n",
        "    \n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(g, p)\n",
        "    \n",
        "    # Plot\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Classification report\n",
        "    print(f\"\\n{title} - Classification Report:\")\n",
        "    print(classification_report(g, p, target_names=classes, digits=4))\n",
        "\n",
        "# Plot for both models\n",
        "print(\"=\"*60)\n",
        "print(\"CONFUSION MATRIX ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "plot_confusion_matrix(mobilenet_trained, val_dl, train_ds.classes, device, \n",
        "                     title=\"MobileNetV3-Small Confusion Matrix\")\n",
        "plot_confusion_matrix(vit_trained, val_dl, train_ds.classes, device, \n",
        "                     title=\"ViT-Small Confusion Matrix\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Summary\n",
        "\n",
        "This notebook trains two models on the **Trashnet dataset** (6 classes of waste):\n",
        "- **cardboard, glass, metal, paper, plastic, trash**\n",
        "\n",
        "### Models Trained:\n",
        "1. **MobileNetV3-Small** (~1.5M params) - Efficient mobile-optimized CNN\n",
        "2. **ViT-Small** (~22M params) - Vision Transformer with attention mechanism\n",
        "\n",
        "### Training Configuration:\n",
        "- **Optimizer**: AdamW with weight decay (0.05)\n",
        "- **Learning Rate**: 5e-4 (MobileNet), 3e-4 (ViT)\n",
        "- **LR Schedule**: Linear warmup (3 epochs) + Cosine annealing\n",
        "- **Data Augmentation**: RandomResizedCrop, HorizontalFlip, ColorJitter\n",
        "- **Regularization**: Dropout (0.2), DropPath (0.1), Label smoothing (0.1)\n",
        "- **Training**: Mixed precision (FP16) with gradient scaling\n",
        "- **Epochs**: 20\n",
        "- **Batch Size**: 64 (train), 128 (val)\n",
        "- **Class Balancing**: Weighted random sampling\n",
        "\n",
        "### Expected Performance:\n",
        "- **MobileNetV3-Small**: ~85-90% accuracy, fast inference (~5-7ms)\n",
        "- **ViT-Small**: ~88-93% accuracy, moderate inference (~5-6ms)\n",
        "\n",
        "### Output Files:\n",
        "- `mobilenetv3_small_trashnet.pt` - PyTorch checkpoint\n",
        "- `mobilenetv3_small_trashnet.onnx` - ONNX export for deployment\n",
        "- `vit_small_trashnet.pt` - PyTorch checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Test Loading Saved Models\n",
        "# This cell demonstrates how to load and use the saved models\n",
        "\n",
        "def load_model_from_checkpoint(checkpoint_path, device=\"cuda\"):\n",
        "    \"\"\"Load a trained model from checkpoint\"\"\"\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    \n",
        "    # Recreate model\n",
        "    model = timm.create_model(\n",
        "        checkpoint[\"model\"], \n",
        "        pretrained=False,\n",
        "        num_classes=checkpoint[\"num_classes\"]\n",
        "    )\n",
        "    \n",
        "    # Load weights\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    return model, checkpoint[\"classes\"]\n",
        "\n",
        "# Example: Load MobileNetV3-Small\n",
        "print(\"Testing model loading...\")\n",
        "loaded_model, classes = load_model_from_checkpoint(\"mobilenetv3_small_trashnet.pt\", device)\n",
        "print(f\"✓ Loaded MobileNetV3-Small\")\n",
        "print(f\"  Classes: {classes}\")\n",
        "\n",
        "# Quick test inference\n",
        "test_input = torch.randn(1, 3, 224, 224, device=device)\n",
        "with torch.no_grad():\n",
        "    output = loaded_model(test_input)\n",
        "    pred_class = output.argmax(1).item()\n",
        "    print(f\"  Test inference: predicted class {pred_class} ({classes[pred_class]})\")\n",
        "\n",
        "print(\"\\n✓ Model loading and inference working correctly!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
