{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42a0107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python: c:\\Users\\61459\\anaconda3\\python.exe\n",
      "Torch: 2.8.0+cpu | CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, pkgutil\n",
    "print(\"Using Python:\", sys.executable)\n",
    "\n",
    "# install into THIS kernel's interpreter\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torch\", \"torchvision\", \"kagglehub\"])\n",
    "\n",
    "import torch\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7db584b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kagglehub successfully imported.\n"
     ]
    }
   ],
   "source": [
    "# data_preprocessing_script.py\n",
    "# Mandatory Kaggle download → nested-folder detection → resize/augment → loaders + summary\n",
    "\n",
    "from __future__ import annotations\n",
    "import argparse\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Kaggle is REQUIRED\n",
    "try:\n",
    "    import kagglehub  # pip install kagglehub\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"kagglehub is required. Install with: pip install kagglehub\\n\"\n",
    "        f\"Import error: {e}\"\n",
    "    )\n",
    "\n",
    "    \n",
    "print(\"kagglehub successfully imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7060a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility + device pick\n",
    "# ------------------------------\n",
    "def set_seed(seed: int = 56) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def pick_device() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        d = torch.device(\"cuda\")\n",
    "        print(f\"[Device] CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "        return d\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        print(\"[Device] MPS (Apple Metal)\")\n",
    "        return torch.device(\"mps\")\n",
    "    print(\"[Device] CPU\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16ad45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder discovery\n",
    "# ------------------------------\n",
    "def looks_like_class_dir(p: Path) -> bool:\n",
    "    return p.is_dir() and sum(1 for x in p.iterdir() if x.is_dir()) >= 2\n",
    "\n",
    "def find_image_root(start: Path) -> Path:\n",
    "    \"\"\"Handles layouts like <root>/images/images, else falls back to a level containing class dirs.\"\"\"\n",
    "    for c in [start / \"images\" / \"images\", start / \"images\", start]:\n",
    "        if c.exists() and looks_like_class_dir(c):\n",
    "            return c\n",
    "    for child in start.iterdir():\n",
    "        if looks_like_class_dir(child):\n",
    "            return child\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4954883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "# ------------------------------\n",
    "def build_transforms(img_size: int) -> Tuple[transforms.Compose, transforms.Compose]:\n",
    "    mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.03),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "    eval_tf = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "    return train_tf, eval_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3500b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset utils\n",
    "# ------------------------------\n",
    "def ext_filter(only_png: bool):\n",
    "    return (lambda p: str(p).lower().endswith(\".png\")) if only_png else None\n",
    "\n",
    "def stratified_split_indices(targets: List[int], val_ratio: float, seed: int):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    targets = np.array(targets)\n",
    "    tr, va = [], []\n",
    "    for c in np.unique(targets):\n",
    "        idx = np.where(targets == c)[0]\n",
    "        rng.shuffle(idx)\n",
    "        n_val = max(1, int(round(len(idx) * val_ratio)))\n",
    "        va += idx[:n_val].tolist()\n",
    "        tr += idx[n_val:].tolist()\n",
    "    rng.shuffle(tr); rng.shuffle(va)\n",
    "    return tr, va\n",
    "\n",
    "def load_from_folder(\n",
    "    data_root: Path, img_size: int, val_ratio: float, seed: int, only_png: bool,\n",
    ") -> Tuple[DataLoader, DataLoader, Optional[DataLoader], Dict]:\n",
    "    train_tf, eval_tf = build_transforms(img_size)\n",
    "    filt = ext_filter(only_png)\n",
    "\n",
    "    has_train = (data_root / \"train\").is_dir()\n",
    "    has_val   = (data_root / \"val\").is_dir()\n",
    "    has_test  = (data_root / \"test\").is_dir()\n",
    "\n",
    "    if has_train and has_val:\n",
    "        train_ds = datasets.ImageFolder(str(find_image_root(data_root / \"train\")), transform=train_tf, is_valid_file=filt)\n",
    "        val_ds   = datasets.ImageFolder(str(find_image_root(data_root / \"val\")),   transform=eval_tf,   is_valid_file=filt)\n",
    "        test_ds  = datasets.ImageFolder(str(find_image_root(data_root / \"test\")),  transform=eval_tf,   is_valid_file=filt) if has_test else None\n",
    "        classes = train_ds.classes\n",
    "    else:\n",
    "        class_root = find_image_root(data_root)\n",
    "        raw = datasets.ImageFolder(str(class_root), transform=None, is_valid_file=filt)\n",
    "        classes = raw.classes\n",
    "        targets = getattr(raw, \"targets\", [lbl for _, lbl in raw.samples])\n",
    "        tr_idx, va_idx = stratified_split_indices(targets, val_ratio, seed)\n",
    "        tr_full = datasets.ImageFolder(str(class_root), transform=train_tf, is_valid_file=filt)\n",
    "        va_full = datasets.ImageFolder(str(class_root), transform=eval_tf,  is_valid_file=filt)\n",
    "        train_ds = Subset(tr_full, tr_idx)\n",
    "        val_ds   = Subset(va_full, va_idx)\n",
    "        test_ds  = None\n",
    "\n",
    "    train_ld = DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "    val_ld   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_ld  = DataLoader(test_ds,  batch_size=64, shuffle=False, num_workers=2, pin_memory=True) if test_ds else None\n",
    "\n",
    "    meta = {\"classes\": classes, \"img_size\": img_size}\n",
    "    return train_ld, val_ld, test_ld, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "040c9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Kaggle (mandatory, fixed dataset)\n",
    "# ------------------------------\n",
    "def download_kaggle_dataset() -> Path:\n",
    "    \"\"\"\n",
    "    Downloads the recyclable and household waste dataset from KaggleHub.\n",
    "    Returns the local dataset path as a Path object.\n",
    "    \"\"\"\n",
    "    import kagglehub\n",
    "    slug = \"alistairking/recyclable-and-household-waste-classification\"\n",
    "    print(f\"[Kaggle] Downloading '{slug}' ...\")\n",
    "    path = kagglehub.dataset_download(slug)\n",
    "    print(f\"[Kaggle] Downloaded to: {path}\")\n",
    "    return Path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e9b2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLI\n",
    "# ------------------------------\n",
    "def main():\n",
    "    p = argparse.ArgumentParser(description=\"Image data preprocessing with mandatory Kaggle download\")\n",
    "    p.add_argument(\"--kaggle\", type=str, required=True, help=\"Kaggle dataset slug, e.g. 'owner/dataset'\")\n",
    "    p.add_argument(\"--img-size\", type=int, default=224)\n",
    "    p.add_argument(\"--val-ratio\", type=float, default=0.1)\n",
    "    p.add_argument(\"--seed\", type=int, default=56)\n",
    "    p.add_argument(\"--png-only\", action=\"store_true\", help=\"Filter to .png images only\")\n",
    "    args = p.parse_args()\n",
    "\n",
    "    set_seed(args.seed)\n",
    "    device = pick_device()\n",
    "\n",
    "    dl_root = download_kaggle_dataset(args.kaggle)\n",
    "    data_root = find_image_root(dl_root)\n",
    "\n",
    "    train_ld, val_ld, test_ld, meta = load_from_folder(\n",
    "        data_root=data_root,\n",
    "        img_size=args.img_size,\n",
    "        val_ratio=args.val_ratio,\n",
    "        seed=args.seed,\n",
    "        only_png=args.png_only,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f3b7f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summary helper (drop-in) ---\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "def summarize_loaders(train_ld, val_ld, test_ld, meta, device):\n",
    "    def ds_len(obj):\n",
    "        if obj is None:\n",
    "            return 0\n",
    "        # Accept DataLoader, Dataset, or Subset\n",
    "        base = getattr(obj, \"dataset\", obj)\n",
    "        return len(base)\n",
    "\n",
    "    print(\"\\n=== DATA SUMMARY ===\")\n",
    "    print(f\"Device: {device.type.upper()}\")\n",
    "    classes = meta.get(\"classes\", [])\n",
    "    preview = classes[:10]\n",
    "    print(f\"Classes ({len(classes)}): {preview}{' ...' if len(classes) > 10 else ''}\")\n",
    "    print(f\"Train: {ds_len(train_ld)} | Val: {ds_len(val_ld)} | Test: {ds_len(test_ld)}\")\n",
    "    try:\n",
    "        # Peek one batch (won't crash if dataset is empty/corrupt)\n",
    "        xb, yb = next(iter(train_ld))\n",
    "        print(f\"Sample batch: images={tuple(xb.shape)}  labels={tuple(yb.shape)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Warn] Could not fetch a batch: {e}\")\n",
    "    print(\"====================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "287a8707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Device] CPU\n",
      "[Kaggle] Downloading 'alistairking/recyclable-and-household-waste-classification' ...\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/alistairking/recyclable-and-household-waste-classification?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 920M/920M [01:02<00:00, 15.4MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Kaggle] Downloaded to: C:\\Users\\61459\\.cache\\kagglehub\\datasets\\alistairking\\recyclable-and-household-waste-classification\\versions\\1\n",
      "\n",
      "=== DATA SUMMARY ===\n",
      "Device: CPU\n",
      "Classes (30): ['aerosol_cans', 'aluminum_food_cans', 'aluminum_soda_cans', 'cardboard_boxes', 'cardboard_packaging', 'clothing', 'coffee_grounds', 'disposable_plastic_cutlery', 'eggshells', 'food_waste'] ...\n",
      "Train: 12000 | Val: 3000 | Test: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\61459\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample batch: images=(64, 3, 224, 224)  labels=(64,)\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- RUN PIPELINE IN NOTEBOOK ----\n",
    "# Settings you can tweak\n",
    "IMG_SIZE  = 224\n",
    "VAL_RATIO = 0.2\n",
    "SEED      = 56\n",
    "PNG_ONLY  = True  # set False to accept jpg/jpeg too\n",
    "\n",
    "# 1) seed + device\n",
    "set_seed(SEED)\n",
    "device = pick_device()\n",
    "\n",
    "# 2) download fixed Kaggle dataset (your helper takes no args)\n",
    "dl_root = download_kaggle_dataset()    # <-- uses the fixed slug inside\n",
    "data_root = find_image_root(dl_root)   # handles images/images nesting\n",
    "\n",
    "# 3) build loaders\n",
    "train_ld, val_ld, test_ld, meta = load_from_folder(\n",
    "    data_root=data_root,\n",
    "    img_size=IMG_SIZE,\n",
    "    val_ratio=VAL_RATIO,\n",
    "    seed=SEED,\n",
    "    only_png=PNG_ONLY,\n",
    ")\n",
    "\n",
    "# 4) print summary\n",
    "summarize_loaders(train_ld, val_ld, test_ld, meta, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
