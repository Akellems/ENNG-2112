{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42a0107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python: c:\\Users\\61459\\anaconda3\\python.exe\n",
      "Torch: 2.8.0+cpu | CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# --- BASIC SETUP: make sure Python path and required packages are ready ---\n",
    "import sys, subprocess, pkgutil\n",
    "print(\"Using Python:\", sys.executable)\n",
    "\n",
    "# Install/upgrade pip and make sure torch/torchvision/kagglehub are available in THIS Python\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torch\", \"torchvision\", \"kagglehub\"])\n",
    "\n",
    "import torch\n",
    "print(\"Torch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7db584b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kagglehub successfully imported.\n"
     ]
    }
   ],
   "source": [
    "# data_preprocessing_script.py\n",
    "# Mandatory Kaggle download → nested-folder detection → resize/augment → loaders + summary\n",
    "\n",
    "\n",
    "# === data_preprocessing_script.py ===\n",
    "# Goal: (1) Download dataset from Kaggle → (2) find correct image folder\n",
    "#       (3) build image transforms (resize/augment/normalize)\n",
    "#       (4) build DataLoaders → (5) print a quick summary\n",
    "\n",
    "from __future__ import annotations\n",
    "import argparse\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Dict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Kaggle is REQUIRED\n",
    "try:\n",
    "    import kagglehub  # pip install kagglehub\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"kagglehub is required. Install with: pip install kagglehub\\n\"\n",
    "        f\"Import error: {e}\"\n",
    "    )\n",
    "\n",
    "    \n",
    "print(\"kagglehub successfully imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7060a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- REPRODUCIBILITY + DEVICE PICKING ---\n",
    "# set_seed: makes \"random\" things repeatable so results are consistent\n",
    "def set_seed(seed: int = 56) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def pick_device() -> torch.device:\n",
    "    if torch.cuda.is_available():\n",
    "        d = torch.device(\"cuda\")\n",
    "        print(f\"[Device] CUDA: {torch.cuda.get_device_name(0)}\")\n",
    "        return d\n",
    "    if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        print(\"[Device] MPS (Apple Metal)\")\n",
    "        return torch.device(\"mps\")\n",
    "    print(\"[Device] CPU\")\n",
    "    return torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16ad45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- FOLDER DISCOVERY ---\n",
    "# looks_like_class_dir: checks if a folder contains 2+ subfolders (typical class directories)\n",
    "def looks_like_class_dir(p: Path) -> bool:\n",
    "    return p.is_dir() and sum(1 for x in p.iterdir() if x.is_dir()) >= 2\n",
    "\n",
    "# find_image_root: tries common nestings like /images/images then falls back\n",
    "def find_image_root(start: Path) -> Path:\n",
    "    \"\"\"Handles layouts like <root>/images/images, else falls back to a level containing class dirs.\"\"\"\n",
    "    for c in [start / \"images\" / \"images\", start / \"images\", start]:\n",
    "        if c.exists() and looks_like_class_dir(c):\n",
    "            return c\n",
    "    for child in start.iterdir():\n",
    "        if looks_like_class_dir(child):\n",
    "            return child\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4954883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TRANSFORMS (image preparation pipelines) ---\n",
    "# build_transforms: training gets random crops/flips/jitter (to generalize);\n",
    "# validation/test get center crop (consistent)\n",
    "def build_transforms(img_size: int) -> Tuple[transforms.Compose, transforms.Compose]:\n",
    "    mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.03),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "    eval_tf = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "    return train_tf, eval_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3500b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- DATASET UTILITIES ---\n",
    "# ext_filter: optional filter so we only accept .png if requested\n",
    "def ext_filter(only_png: bool):\n",
    "    return (lambda p: str(p).lower().endswith(\".png\")) if only_png else None\n",
    "\n",
    "# --- Add this 3-way splitter (keep your existing 2-way version too if you like) ---\n",
    "def stratified_split_indices_3(targets: List[int], val_ratio: float, test_ratio: float, seed: int):\n",
    "    \"\"\"Stratified split into train/val/test by class.\"\"\"\n",
    "    assert 0 < val_ratio < 1 and 0 <= test_ratio < 1 and (val_ratio + test_ratio) < 1, \\\n",
    "        \"val_ratio + test_ratio must be < 1\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    tr, va, te = [], [], []\n",
    "    for c in np.unique(targets):\n",
    "        idx = np.where(targets == c)[0]\n",
    "        rng.shuffle(idx)\n",
    "        n = len(idx)\n",
    "        n_val  = max(1, int(round(n * val_ratio))) if n > 1 else 0\n",
    "        n_test = max(1, int(round(n * test_ratio))) if (test_ratio > 0 and n - n_val > 1) else 0\n",
    "        # cap to avoid overrun on tiny classes\n",
    "        n_val  = min(n_val,  n - 1) if n > 1 else 0\n",
    "        n_test = min(n_test, n - n_val - 1) if (n - n_val) > 1 else 0\n",
    "\n",
    "        va += idx[:n_val].tolist()\n",
    "        te += idx[n_val:n_val + n_test].tolist()\n",
    "        tr += idx[n_val + n_test:].tolist()\n",
    "\n",
    "    rng.shuffle(tr); rng.shuffle(va); rng.shuffle(te)\n",
    "    return tr, va, te\n",
    "\n",
    "\n",
    "\n",
    "# load_from_folder: handles two layouts\n",
    "# (A) separate train/val(/test) folders, or\n",
    "# (B) one big folder → we do a stratified split\n",
    "# --- Replace your entire load_from_folder with this complete version (no ellipses) ---\n",
    "def load_from_folder(\n",
    "    data_root: Path,\n",
    "    img_size: int,\n",
    "    val_ratio: float,\n",
    "    seed: int,\n",
    "    only_png: bool,\n",
    "    test_ratio: float = 0.0,  # NEW\n",
    ") -> Tuple[DataLoader, DataLoader, Optional[DataLoader], Dict]:\n",
    "    \"\"\"\n",
    "    Builds DataLoaders from a folder that is either:\n",
    "      A) already split as data_root/{train,val, test?}, or\n",
    "      B) a single folder of class subfolders (we do a stratified split into train/val/(test)).\n",
    "    \"\"\"\n",
    "    # transforms + optional .png filter\n",
    "    train_tf, eval_tf = build_transforms(img_size)\n",
    "    filt = ext_filter(only_png)\n",
    "\n",
    "    # detect pre-split layout\n",
    "    has_train = (data_root / \"train\").is_dir()\n",
    "    has_val   = (data_root / \"val\").is_dir()\n",
    "    has_test  = (data_root / \"test\").is_dir()\n",
    "\n",
    "    if has_train and has_val:\n",
    "        # Case A: dataset already has train/val/(test) on disk\n",
    "        train_ds = datasets.ImageFolder(str(find_image_root(data_root / \"train\")), transform=train_tf, is_valid_file=filt)\n",
    "        val_ds   = datasets.ImageFolder(str(find_image_root(data_root / \"val\")),   transform=eval_tf,   is_valid_file=filt)\n",
    "        test_ds  = datasets.ImageFolder(str(find_image_root(data_root / \"test\")),  transform=eval_tf,   is_valid_file=filt) if has_test else None\n",
    "        classes = train_ds.classes\n",
    "    else:\n",
    "        # Case B: one folder; do our own stratified split (now 3-way if test_ratio > 0)\n",
    "        class_root = find_image_root(data_root)\n",
    "        raw = datasets.ImageFolder(str(class_root), transform=None, is_valid_file=filt)\n",
    "        classes = raw.classes\n",
    "        targets = getattr(raw, \"targets\", [lbl for _, lbl in raw.samples])\n",
    "\n",
    "        if test_ratio and test_ratio > 0:\n",
    "            tr_idx, va_idx, te_idx = stratified_split_indices_3(targets, val_ratio, test_ratio, seed)\n",
    "        else:\n",
    "            tr_idx, va_idx = stratified_split_indices(targets, val_ratio, seed)\n",
    "            te_idx = []\n",
    "\n",
    "        tr_full = datasets.ImageFolder(str(class_root), transform=train_tf, is_valid_file=filt)\n",
    "        va_full = datasets.ImageFolder(str(class_root), transform=eval_tf,  is_valid_file=filt)\n",
    "        te_full = datasets.ImageFolder(str(class_root), transform=eval_tf,  is_valid_file=filt)\n",
    "\n",
    "        train_ds = Subset(tr_full, tr_idx)\n",
    "        val_ds   = Subset(va_full, va_idx)\n",
    "        test_ds  = Subset(te_full, te_idx) if len(te_idx) > 0 else None\n",
    "\n",
    "    # DataLoaders\n",
    "    train_ld = DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "    val_ld   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_ld  = DataLoader(test_ds,  batch_size=64, shuffle=False, num_workers=2, pin_memory=True) if test_ds else None\n",
    "\n",
    "    meta = {\"classes\": classes, \"img_size\": img_size}\n",
    "    return train_ld, val_ld, test_ld, meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "040c9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KAGGLE DOWNLOAD (fixed dataset helper) ---\n",
    "# download_kaggle_dataset: grabs a specific recycling dataset and returns the local path\n",
    "def download_kaggle_dataset() -> Path:\n",
    "    \"\"\"\n",
    "    Downloads the recyclable and household waste dataset from KaggleHub.\n",
    "    Returns the local dataset path as a Path object.\n",
    "    \"\"\"\n",
    "    import kagglehub\n",
    "    slug = \"alistairking/recyclable-and-household-waste-classification\"\n",
    "    print(f\"[Kaggle] Downloading '{slug}' ...\")\n",
    "    path = kagglehub.dataset_download(slug)\n",
    "    print(f\"[Kaggle] Downloaded to: {path}\")\n",
    "    return Path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e9b2726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLI\n",
    "# ------------------------------\n",
    "def main():\n",
    "    p = argparse.ArgumentParser(description=\"Image data preprocessing with mandatory Kaggle download\")\n",
    "    p.add_argument(\"--kaggle\", type=str, required=True, help=\"Kaggle dataset slug, e.g. 'owner/dataset'\")\n",
    "    p.add_argument(\"--img-size\", type=int, default=224)\n",
    "    p.add_argument(\"--val-ratio\", type=float, default=0.1)\n",
    "    p.add_argument(\"--seed\", type=int, default=56)\n",
    "    p.add_argument(\"--png-only\", action=\"store_true\", help=\"Filter to .png images only\")\n",
    "    args = p.parse_args()\n",
    "\n",
    "    set_seed(args.seed)\n",
    "    device = torch.device(\"cuda\")  # pick_device()  # Device not used in preprocessing\n",
    "\n",
    "    dl_root = download_kaggle_dataset(args.kaggle)\n",
    "    data_root = find_image_root(dl_root)\n",
    "\n",
    "    train_ld, val_ld, test_ld, meta = load_from_folder(\n",
    "        data_root=data_root,\n",
    "        img_size=args.img_size,\n",
    "        val_ratio=args.val_ratio,\n",
    "        seed=args.seed,\n",
    "        only_png=args.png_only,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3b7f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summary helper (drop-in) ---\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "def summarize_loaders(train_ld, val_ld, test_ld, meta, device):\n",
    "    def ds_len(obj):\n",
    "        if obj is None:\n",
    "            return 0\n",
    "        # Accept DataLoader, Dataset, or Subset\n",
    "        base = getattr(obj, \"dataset\", obj)\n",
    "        return len(base)\n",
    "\n",
    "    print(\"\\n=== DATA SUMMARY ===\")\n",
    "    print(f\"Device: {device.type.upper()}\")\n",
    "    classes = meta.get(\"classes\", [])\n",
    "    preview = classes[:10]\n",
    "    print(f\"Classes ({len(classes)}): {preview}{' ...' if len(classes) > 10 else ''}\")\n",
    "    print(f\"Train: {ds_len(train_ld)} | Val: {ds_len(val_ld)} | Test: {ds_len(test_ld)}\")\n",
    "    try:\n",
    "        # Peek one batch (won't crash if dataset is empty/corrupt)\n",
    "        xb, yb = next(iter(train_ld))\n",
    "        print(f\"Sample batch: images={tuple(xb.shape)}  labels={tuple(yb.shape)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Warn] Could not fetch a batch: {e}\")\n",
    "    print(\"====================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "287a8707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Kaggle] Downloading 'alistairking/recyclable-and-household-waste-classification' ...\n",
      "[Kaggle] Downloaded to: C:\\Users\\61459\\.cache\\kagglehub\\datasets\\alistairking\\recyclable-and-household-waste-classification\\versions\\1\n",
      "\n",
      "=== DATA SUMMARY ===\n",
      "Device: CUDA\n",
      "Classes (30): ['aerosol_cans', 'aluminum_food_cans', 'aluminum_soda_cans', 'cardboard_boxes', 'cardboard_packaging', 'clothing', 'coffee_grounds', 'disposable_plastic_cutlery', 'eggshells', 'food_waste'] ...\n",
      "Train: 12000 | Val: 2250 | Test: 750\n",
      "Sample batch: images=(64, 3, 224, 224)  labels=(64,)\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- RUN PIPELINE IN NOTEBOOK ----\n",
    "# Settings you can tweak\n",
    "IMG_SIZE  = 224  # how big each image becomes (square)\n",
    "VAL_RATIO = 0.15  # 15% of data for validation\n",
    "TEST_RATIO = 0.05  # NEW: 5% of data for test (adjust as you like)\n",
    "SEED      = 56   # repeatable split/transforms\n",
    "PNG_ONLY  = True  # set False to accept jpg/jpeg too (only accepts png)\n",
    "\n",
    "# 1) seed + device\n",
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda\")  # pick_device()  # Device not used in preprocessing\n",
    "\n",
    "# 2) download fixed Kaggle dataset (your helper takes no args)\n",
    "dl_root = download_kaggle_dataset()    # <-- uses the fixed slug inside\n",
    "data_root = find_image_root(dl_root)   # handles images/images nesting\n",
    "\n",
    "# 3) build loaders\n",
    "train_ld, val_ld, test_ld, meta = load_from_folder(\n",
    "    data_root=data_root,\n",
    "    img_size=IMG_SIZE,\n",
    "    val_ratio=VAL_RATIO,\n",
    "    seed=SEED,\n",
    "    only_png=PNG_ONLY,\n",
    "    test_ratio=TEST_RATIO,  # NEW: request a test split when dataset isn't pre-split\n",
    ")\n",
    "\n",
    "# 4) print summary\n",
    "summarize_loaders(train_ld, val_ld, test_ld, meta, device)\n",
    "\n",
    "#Prints the first 10 class labels so you can sanity-check the naming \n",
    "#Meaning: After the 80/20 split (because VAL_RATIO = 0.2), you’ve got 12,000 training images and 3,000 validation images. There’s no test set in this dataset layout, so it shows 0.\n",
    "#Meaning: We successfully pulled one training batch.\n",
    "#images=(64, 3, 224, 224) = 64 images per batch, 3 color channels (RGB), and each image is 224×224 pixels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b635d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
